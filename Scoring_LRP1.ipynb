{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e272069",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup and Data Loading\n",
    "This cell initializes the workspace by importing necessary libraries and loading the raw data from your Excel file.\n",
    "\n",
    "* **Libraries:** We use pandas for data manipulation and numpy for conditional logic.\n",
    "\n",
    "* **Data Sources:** It loads the main interaction database (LRP-IntDB) and the Detection Techniques dictionary (DT), which contains the classification for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "669d7768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database loaded: 623 rows.\n",
      "âœ… Detection Technique (DT) dictionary loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File path definition\n",
    "file_path = 'LRP-IntDB (30).xlsx'\n",
    "\n",
    "# Load the full Excel file\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load the main database sheet\n",
    "df_main = xl.parse('LRP-IntDB')\n",
    "\n",
    "# Load the Detection Technique (DT) dictionary\n",
    "# Header=1 is used because the DT sheet has a specific metadata structure in the first row\n",
    "df_dt = xl.parse('DT', header=1) \n",
    "\n",
    "print(f\"âœ… Database loaded: {len(df_main)} rows.\")\n",
    "print(f\"âœ… Detection Technique (DT) dictionary loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59e453",
   "metadata": {},
   "source": [
    "## Cell 2: Building the Technique Mapping\n",
    "To calculate scores, we need to know if a technique is Genomic, Protein, or Cell-based. This cell creates a \"lookup dictionary\" from the Excel sheet.\n",
    "\n",
    "* **Logic:** It iterates through the columns of the DT sheet and maps every technique name to its respective category.\n",
    "\n",
    "* **Purpose:** This allows the script to instantly categorize any technique found in the main database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a72d478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dictionary built: 35 classified techniques.\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping: Technique Name -> Category (Group)\n",
    "tech_to_group = {}\n",
    "\n",
    "# Define dictionary columns based on the Excel structure\n",
    "columnas_grupos = {\n",
    "    'Genomic Experiments': 'Genomic',\n",
    "    'Protein Experiments': 'Protein',\n",
    "    'Cell Experiments': 'Cell'\n",
    "}\n",
    "\n",
    "for col_excel, grupo_id in columnas_grupos.items():\n",
    "    if col_excel in df_dt.columns:\n",
    "        # Extract techniques, remove nulls and trim whitespace\n",
    "        tecnicas = df_dt[col_excel].dropna().unique()\n",
    "        for t in tecnicas:\n",
    "            tech_to_group[t.strip()] = grupo_id\n",
    "\n",
    "print(f\"ðŸ“Š Dictionary built: {len(tech_to_group)} classified techniques.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1d390d",
   "metadata": {},
   "source": [
    "## Cell 3: Data Pre-processing and Expansion\n",
    "Before scoring, we must clean the data and handle rows that contain multiple techniques separated by commas.\n",
    "\n",
    "* **ProteinID:** We create a unique identifier. If a Uniprot ID is missing (*), we generate a temporary ID using the protein's name.\n",
    "\n",
    "* **Explode Logic:** Many rows list techniques like \"Western Blot, ELISA\". This cell splits them into individual rows so each experiment is counted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60f40985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Data pre-processing complete.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a consistent unique ID for proteins\n",
    "df_main['ProteinID'] = np.where(\n",
    "    (df_main['ID Uniprot A'] != '*') & (df_main['ID Uniprot A'].notna()), \n",
    "    df_main['ID Uniprot A'], \n",
    "    \"NAME_\" + df_main['Protein Name A'].str.replace(' ', '_').str.replace(':', '')\n",
    ")\n",
    "\n",
    "# 2. Clean 'Cell Type' column\n",
    "df_main['Cell Type'] = df_main['Cell Type'].fillna('*').astype(str).str.strip()\n",
    "\n",
    "# 3. Technique Expansion (Explode)\n",
    "# Splits comma-separated strings into individual rows\n",
    "df_expanded = df_main.assign(\n",
    "    Technique=df_main['Detection technique'].str.split(',')\n",
    ").explode('Technique')\n",
    "\n",
    "df_expanded['Technique'] = df_expanded['Technique'].str.strip()\n",
    "\n",
    "print(f\"ðŸ“ˆ Data pre-processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb53fa2",
   "metadata": {},
   "source": [
    "## Cell 4: The Scoring Algorithm (The \"Golden Rule\")\n",
    "This is the core of the script. It calculates the interaction confidence score based on experimental evidence and inheritance.\n",
    "\n",
    "* **Scoring Weights: Binary** techniques receive a flat $0.35$. **HTS** (High-Throughput) techniques start at $0.25$ and decrease by $0.05$ for every additional experiment in the same category to prevent \"easy\" inflation.\n",
    "\n",
    "* **Inheritance Logic:**\n",
    "\n",
    "    1. **Triple Star ( * , * ,*):** Pure global evidence. These rows calculate their own score.\n",
    "\n",
    "    2. **Has Organism:** Rows with no Cell Type but specific Organism data. They inherit evidence from the Triple Star.\n",
    "\n",
    "    3. **Specific Cell Type:** Rows with a named cell (e.g., \"Hepatocyte\"). They inherit evidence from the Triple Star.\n",
    "    \n",
    "* **Normalization:** The final sum is divided by $1.1$ and capped at $1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17aec132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scoring process completed.\n"
     ]
    }
   ],
   "source": [
    "def calculate_group_score(rows):\n",
    "    BINARY_WEIGHT = 0.35\n",
    "    HTS_BASE_WEIGHT = 0.25\n",
    "    HTS_REDUCTION_STEP = 0.05\n",
    "    MIN_HTS_WEIGHT = 0.05\n",
    "    total_score = 0\n",
    "    group_counts = {'Genomic': 0, 'Protein': 0, 'Cell': 0}\n",
    "    \n",
    "    for _, row in rows.iterrows():\n",
    "        tech = str(row['Technique'])\n",
    "        td_type = str(row['TD Type'])\n",
    "        category = tech_to_group.get(tech, 'Protein') \n",
    "        \n",
    "        if 'Binary' in td_type:\n",
    "            weight = BINARY_WEIGHT\n",
    "        else:\n",
    "            count = group_counts.get(category, 0)\n",
    "            weight = max(MIN_HTS_WEIGHT, HTS_BASE_WEIGHT - (count * HTS_REDUCTION_STEP))\n",
    "            group_counts[category] += 1\n",
    "        total_score += weight\n",
    "    \n",
    "    return min(total_score / 1.1, 1.0)\n",
    "\n",
    "# 1. Clean columns for grouping\n",
    "for col in ['Cell Type', 'Organism', 'Cell line/ Tissue']:\n",
    "    df_expanded[col] = df_expanded[col].fillna('*').astype(str).str.strip()\n",
    "\n",
    "# 2. Group Labeling Logic\n",
    "def get_final_group_label(row):\n",
    "    p_id = row['ProteinID']\n",
    "    c_type = row['Cell Type']\n",
    "    org = row['Organism']\n",
    "    c_line = row['Cell line/ Tissue']\n",
    "    \n",
    "    if c_type == '*' and org == '*' and c_line == '*':\n",
    "        return f\"{p_id}_TRIPLE_STAR\"\n",
    "    if c_type == '*' and org != '*':\n",
    "        return f\"{p_id}_HAS_ORGANISM\"\n",
    "    return f\"{p_id}_{c_type}\"\n",
    "\n",
    "df_expanded['Group_Label'] = df_expanded.apply(get_final_group_label, axis=1)\n",
    "\n",
    "# 3. Calculate Scores per Group\n",
    "final_results = []\n",
    "unique_labels = df_expanded['Group_Label'].unique()\n",
    "\n",
    "for label in unique_labels:\n",
    "    specific_rows = df_expanded[df_expanded['Group_Label'] == label]\n",
    "    p_id = specific_rows.iloc[0]['ProteinID']\n",
    "    \n",
    "    # Non-global groups inherit evidence from the 'TRIPLE_STAR' group\n",
    "    if \"_TRIPLE_STAR\" not in label:\n",
    "        wildcards = df_expanded[df_expanded['Group_Label'] == f\"{p_id}_TRIPLE_STAR\"]\n",
    "        evidence_pool = pd.concat([specific_rows, wildcards]).drop_duplicates()\n",
    "    else:\n",
    "        evidence_pool = specific_rows\n",
    "        \n",
    "    score = calculate_group_score(evidence_pool)\n",
    "    final_results.append({'Group_Label': label, 'Score': score})\n",
    "\n",
    "# 4. Final Integration\n",
    "scores_map = pd.DataFrame(final_results)\n",
    "df_final = df_main.copy()\n",
    "for col in ['Cell Type', 'Organism', 'Cell line/ Tissue']:\n",
    "    df_final[col] = df_final[col].fillna('*').astype(str).str.strip()\n",
    "\n",
    "df_final['Group_Label'] = df_final.apply(get_final_group_label, axis=1)\n",
    "df_final = df_final.merge(scores_map, on='Group_Label', how='left').drop(columns=['Group_Label'])\n",
    "\n",
    "print(f\"âœ… Scoring process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb4f6c",
   "metadata": {},
   "source": [
    "## Cell 5: Exporting the Final Dataset\n",
    "Finally, we clean up the temporary columns used for calculation and save the result into a new Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4c251ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Final file saved as: LRP-IntDB_Final_Scored.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a safe copy\n",
    "df_to_save = df_final.copy()\n",
    "\n",
    "# 2. Remove the temporary ProteinID column to restore the original 'ID Uniprot A' look\n",
    "if 'ProteinID' in df_to_save.columns:\n",
    "    df_to_save = df_to_save.drop(columns=['ProteinID'])\n",
    "\n",
    "# 3. Save to Excel\n",
    "output_file = 'LRP-IntDB_Final_Scored.xlsx'\n",
    "df_to_save.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"ðŸŽ‰ Final file saved as: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
